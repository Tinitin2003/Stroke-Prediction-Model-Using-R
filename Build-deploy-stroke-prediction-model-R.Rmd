---
title: "Build and deploy a stroke prediction model using R"
date: "`r Sys.Date()`"
output: html_document
author: "Nitin Panwar!"
---

# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on building and deploying a stroke prediction model in R. It contains analysis such as data exploration, summary statistics and building the prediction models. The final report was completed on `r date()`. 

**Data Description:**

According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.

This data set is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relevant information about the patient.


# Task One: Import data and data preprocessing

## Load data and install packages

```{r}
#install.packages("tidyverse")
#install.packages("tidymodels")
#install.packages("ranger")
library(tidymodels)
library(tidyverse)
library(dplyr)
library(readr)
library(skimr)
filename<-"healthcare-dataset-stroke-data.csv"
dataset <- read.csv(filename,header = TRUE,na.strings=c("N/A","NA"))
dataset <- dataset %>%
  mutate_all(~ ifelse(. == "Unknown", NA, .))
str(dataset)

```


## Describe and explore the data

```{r}
#dimension of dataset
dim(dataset)

#summarize attribute distributions
skim(dataset)

# list types for each attribute
sapply(dataset, class)


# take a peek at the first 5 rows of the data
head(dataset)

# list the levels for the class
unique(dataset$stroke)
unique(dataset$gender)
unique(dataset$hypertension)
unique(dataset$heart_disease)
unique(dataset$ever_married)
unique(dataset$work_type)
unique(dataset$Residence_type)
unique(dataset$smoking_status)
#remove the id
#dataset<-
#  select(dataset,-id)
#observe first rows
head(dataset)


#install.packages("DataExplorer")
library(DataExplorer)
#plot_str(df) plots the dataset structure
plot_str(dataset)
#plot_bar(df) plots the bar chart for each discrete feature
plot_bar(dataset)
#The charts can also be grouped by a discrete variable, e.g. the presence of a cardiovascular disease, by: plot_bar(df, by="cardio")
plot_bar(dataset, by="stroke")
#plot_qq(df) plots quantile-quantile for each continuous feature
plot_qq(dataset)
#plot_density(df) plots density estimates for each continuous feature
plot_density(dataset)
#plot_correlation(df) to visualize correlation heatmap
plot_correlation(dataset)
#plot_prcomp(df) performs Principal Component Analysis (PCA) and plots the percentage of variance explained by each principal component
#plot_prcomp(dataset)

#check the number of missing values for each column N/A<>NA =>all 0 in counting null
sapply(dataset,function(x) sum(is.na(x)))

##Calculate the proportion of missingness for each variable
dataset %>%
  map(is.na) %>%
  map(sum)%>%
  map(~./nrow(dataset))%>%
  bind_cols()
##Drop rows with NA values in column
dataset <- dataset %>%
  drop_na(bmi)
dataset <- dataset %>%
  drop_na(smoking_status)
dim(dataset)

#check the number of missing values for each column N/A<>NA =>all 0 in counting null
sapply(dataset,function(x) sum(is.na(x)))
```



# Task Two: Build prediction models

```{r}
set.seed(234589)
dataset$stroke <- factor(dataset$stroke)
# split the data into trainng (75%) and testing (25%)
dataset_split <- initial_split(dataset, 
                                prop = 3/4)
dataset_split

# extract training and testing sets
dataset_train <- training(dataset_split)
dataset_test <- testing(dataset_split)

# create CV object from training data
dataset_cv <- vfold_cv(dataset_train)

# define the recipe
stroke_recipe <- 
# which consists of the formula (outcome ~ predictors)
  recipe(stroke ~  gender + age + hypertension + heart_disease + 
           ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, 
         data = dataset) 
stroke_recipe

rf_model <- 
  # specify that the model is a random forest
  rand_forest() %>%
  # specify that the `mtry` parameter needs to be tuned
  set_args(mtry = tune()) %>%
  # select the engine/package that underlies the model
  set_engine("ranger", importance = "impurity") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification") 

lr_model <- 
  # specify that the model is a logistic regression
  logistic_reg() %>%
  # select the engine/package that underlies the model
  set_engine("glm") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("classification")

knn_model <- 
  nearest_neighbor(weight_func = "rectangular", neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification")


# set the workflow
rf_workflow <- workflow() %>%
  # add the recipe
  add_recipe(stroke_recipe) %>%
  # add the model
  add_model(rf_model)
  

# specify which values eant to try
rf_grid <- expand.grid(mtry = c(3, 4, 5))
# Specify which values to try for neighbors
knn_grid <- expand.grid(neighbors = c(5, 10, 15))


# extract results
rf_tune_results <- rf_workflow %>%
  tune_grid(resamples = dataset_cv, #CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(accuracy, roc_auc) # metrics we care about
            )

# print results
rf_tune_results %>%
  collect_metrics()

param_final <- rf_tune_results %>%
  select_best(metric = "accuracy")
param_final

rf_workflow <- rf_workflow %>%
  finalize_workflow(param_final)



```




# Task Three: Evaluate and select prediction models

```{r}

rf_fit <- rf_workflow %>%
  # fit on the training set and evaluate on test set
  last_fit(dataset_split)
rf_fit

test_performance <- rf_fit %>% collect_metrics()
test_performance

# generate predictions from the test set
test_predictions <- rf_fit %>% collect_predictions()
test_predictions

# generate a confusion matrix
test_predictions %>% 
  conf_mat(truth = stroke, estimate = .pred_class)

final_model <- fit(rf_workflow, dataset)

final_model

saveRDS(final_model, "model.rds")
```



# Task Four: Deploy the prediction model

```{r}
library(shiny)
library(shinythemes)
library(data.table)

####################################
# User interface                   #
####################################

ui <- fluidPage(theme = shinytheme("cyborg"),
  
  # Page header
  headerPanel('Possibility of Stroke?'),
  
  # Input values
  sidebarPanel(
    HTML("<h3>Input parameters</h3>"),
    
    selectInput("gender", label = "Gender:", 
                choices = list("Male" = "Male", "Female" = "Female", "Other" = "Other"), 
                selected = "Male"),
    sliderInput("age", "Age:",
                min = 10, max = 82,
                value = 50),
    selectInput("hypertension", label = "Hybertension:", 
                choices = list("Yes" = 1, "No" = 0), 
                selected = 1),
    selectInput("heart_disease", label = "Heart Diseases:", 
                choices = list("Yes" = 1, "No" = 0), 
                selected = 1),
    selectInput("ever_married", label = "Ever Married:", 
                choices = list("Yes" = "Yes", "No" = "No"), 
                selected = 1),
     selectInput("work_type", label = "Work Type:", 
                choices = list("Private" = "Private", "Self Employed" = "Self-employed","Govt. Job"= "Govt_job"), 
                selected = "Private"),
     selectInput("Residence_type", label = "Residence Type:", 
                choices = list("Urban" = "Urban", "Rural" = "Rural"), 
                selected = "Urban"),
    sliderInput("avg_glucose_level", "Average Glucose Level:",
                min = 55.12, max = 271.74,
                value = 90),
    sliderInput("bmi", "BMI:",
                min = 11.5, max = 92,
                value = 18.5),
    selectInput("smoking_status", label = "Smoking Status:", 
                choices = list("Smoker" = "smokes", "Formerly smoked" = "formerly smoked","Never smoked"="never smoked"), 
                selected = "never smoked"),
    
    actionButton("submitbutton", "Submit", class = "btn btn-primary")
  ),
  
  mainPanel(
    tags$label(h3('Status/Output')), # Status/Output Text Box
    verbatimTextOutput('contents'),
    tableOutput('tabledata') # Prediction results table
    
  )
)

####################################
# Server                           #
####################################

server <- function(input, output, session) {

  # Input Data
  datasetInput <- reactive({  
    
  # outlook,temperature,humidity,windy,play
  df <- data.frame(
    Name = c("gender",
             "age",
             "hypertension",
             "heart_disease",
             "ever_married",
             "work_type",
             "Residence_type",
             "avg_glucose_level",
             "bmi",
             "smoking_status"
             ),
    Value = as.character(c(input$gender,
                           input$age,
                           input$hypertension,
                           input$heart_disease,
                           input$ever_married,
                           input$work_type,
                           input$Residence_type,
                           input$avg_glucose_level,
                           input$bmi,
                           input$smoking_status)),
    stringsAsFactors = FALSE)
  
  
  play <- "play"
  df <- rbind(df, play)
  input <- transpose(df)
  write.table(input,"input.csv", sep=",", quote = FALSE, row.names = FALSE, col.names = FALSE)
  
  test <- read.csv(paste("input", ".csv", sep=""), header = TRUE)
  
  test$stroke <- factor(test$smoking_status, levels = c(1, 0))
  
  
  Output <- data.frame(Prediction=predict(final_model,test), round(predict(final_model,test,type="prob"), 2))
  print(Output)
  
  })
  
  # Status/Output Text Box
  output$contents <- renderPrint({
    if (input$submitbutton>0) { 
      isolate("Calculation complete.") 
    } else {
      return("Server is ready for calculation.")
    }
  })
  
  # Prediction results table
  output$tabledata <- renderTable({
    if (input$submitbutton>0) { 
      isolate(datasetInput()) 
    } 
  })
  
}

####################################
# Create the shiny app             #
####################################
shinyApp(ui = ui, server = server)
```




# Task Five: Findings and Conclusions


Key Findings:

Data Exploration:

The dataset includes information on various factors such as gender, age, hypertension, heart disease, marital status, work type, residence type, average glucose level, BMI, and smoking status.
Initial exploration revealed the presence of missing values, which were addressed through imputation and removal of rows with missing data.
Model Building:

Three models, namely Random Forest, Logistic Regression, and k-Nearest Neighbors, were trained to predict stroke occurrence based on the provided features.
Random Forest was selected as the final model, and hyperparameter tuning was performed to optimize its performance.
Model Evaluation:

The Random Forest model demonstrated promising accuracy and ROC-AUC values during evaluation on the test set.
The finalized model is capable of predicting stroke occurrence based on the input parameters with a reasonable level of confidence.
Conclusion:

In conclusion, the analysis successfully explored, built, and evaluated a stroke prediction model using R. The chosen Random Forest model exhibited strong predictive performance. The Shiny app developed for model deployment provides a user-friendly interface for predicting stroke likelihood based on user input. This project contributes to the understanding and prediction of stroke risks, offering a valuable tool for healthcare professionals and individuals seeking personalized health insights.




































